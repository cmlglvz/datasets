---
title: "Funciones"
output: html_document
---

## Libraries

```{r echo=TRUE, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(data.table)
library(grDevices)
library(BiodiversityR)
library(vegan)
library(treemap)
library(d3treeR)
library(htmlwidgets)
library(ComplexHeatmap)
library(circlize)
library(UpSetR)
library(RColorBrewer)
library(viridis)
library(ggsci)
library(ggvegan)
library(ggpubr)
```


## Dataframes

```{r, echo=TRUE, message=TRUE, warning=TRUE}
#DF with identified ASV by DADA2
ASVs <- read.csv("E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/seqtab_nochim.csv", header = T, sep = ";", dec = '.', skip = 0)
ASVs <- mutate(ASVs, Sample = c("C1_2017.04", "C1_2018.02", "C1_2018.04", "C2_2017.04", "C2_2018.02", "C2_2018.04", "C3_2017.04", "C3_2018.02", "C3_2018.04", "C4_2017.04", "C4_2018.02", "C4_2018.04", "F1_2017.04", "F1_2018.02", "F1_2018.04", "F2_2017.04", "F2_2018.02", "F2_2018.04", "F3_2017.04", "F3_2018.02", "F3_2018.04", "F4_2017.04", "F4_2018.02", "F4_2018.04", "H1_2017.04", "H1_2018.02", "H1_2018.04", "H2_2017.04", "H2_2018.02", "H2_2018.04", "H3_2017.04", "H3_2018.02", "H3_2018.04", "H4_2017.04", "H4_2018.02", "H4_2018.04", "P1_2018.02", "P1_2018.04", "P2_2018.02", "P3_2018.02", "P4_2018.02"), 
               .after = "X")
SN <- ASVs[,2]
ASVs <- ASVs[,-c(1, 2)]
ASVs <- apply(ASVs, 2, function(x) as.numeric(as.integer(x))) %>% as.data.frame()
rownames(ASVs) <- SN
write.csv2(ASVs, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/ASVs.csv") #Saving some DF necessary for downstream analysis

#ASV assigned taxa from PR2 4.14 
TXs <- read.csv("E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/taxa_pr2.csv", header = T, sep = ";", dec = '.', skip = 0) %>% rename(Seq = X) %>% add_column(OTU = c(paste0("ASV_", 1:4261)), .after = "Seq") #better identification throughout the analysis 
rownames(TXs) <- TXs[,1]
write.csv2(TXs, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/TXs.csv")

print(all(colnames(ASVs)%in%rownames(TXs))) #If TRUE you can continue

#Drop non-PPE taxa, we we'll use "Division" as a staring point.
fTXs <- TXs %>% filter(Division == "Chlorophyta" | Division == "Ochrophyta" | Division == "Cryptophyta" | Division == "Cryptophyta:nucl" | Division == "Haptophyta" | Division == "Katablepharidophyta" | Division == "Rhodophyta" | Division == "Stramenopiles_X" | Division == "Alveolata_X") #Unrefined data filtering
write.csv2(fTXs, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/fTXs.csv")

#If for some reason you want to get rid of NA assignations across all ASVs you can perform this
value.na <- fTXs[rowSums(is.na(fTXs)) > 0,]
value <- fTXs[complete.cases(fTXs), ] #You continue with this object
print(nrow(value.na)+nrow(value)) == count(fTXs)

xSN <- fTXs[, 1]
xASVs <- select(ASVs, all_of(xSN)) #DF with selected PPE Divisions' ASV across all samples 
print(all(colnames(xASVs)%in%rownames(fTXs))) #Just in case
write.csv2(xASVs, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/xASVs.csv")

```


## Rarefaction
Rarefaction is a technique to assess expected species richness. It allows the calculation of species richness for a given number of individual samples, based on the construction of rarefaction curves. The issue that occurs when sampling various species in a community is that the larger the number of individuals sampled, the more species that will be found. Rarefaction curves are created by randomly re-sampling the pool of N samples multiple times and then plotting the average number of species found in each sample (1,2, … N). “Thus rarefaction generates the expected number of species in a small collection of n individuals (or n samples) drawn at random from the large pool of N samples.”. Rarefaction curves generally grow rapidly at first, as the most common species are found, but the curves plateau as only the rarest species remain to be sampled.

```{r, echo=TRUE, message=TRUE, warning=TRUE}
raremax <- sort(rowSums(xASVs))
raremax
plot(raremax)

TSRrfy<- rarefy(xASVs, raremax[1]) #rarefaction uses the smallest number of observations per sample to extrapolate the expected number if all other samples only had that number of observations
TSRrfy #gives an "expected"rarefied" number of species (not obs) if only 732 individuals were present

kols <- viridis(41)
#paletapers <- colorRampPalette(c("#FF0000", "#FA8072", "#DC143C", "#CD5C5C", "#FF1493", "#FFC0CB", "#C71585", "#FF69B4", "#FF4500", "#FF4500", "#FF7F50", "#FFFF00", "#BDB76B", "#FFDAB9", "#FFD700", "#F0E68C", "#FFE4B5", "#4B0082", "#8B008B", "#FF00FF", "#9370DB", "#9400D3", "#E6E6FA", "#D8BFD8", "#ADFF2F", "#7FFF00", "#00FF00", "#98FB98", "#00FA9A", "#2E8B57", "#006400", "#808000", "#556B2F", "#66CDAA", "#8FBC8B", "#008080", "#00FFFF", "#AFEEEE", "#7FFFD4", "#40E0D0", "#5F9EA0", "#4682B4", "#B0C4DE", "#87CEEB", "#00BFFF", "#1E90FF", "#4169E1", "#000080", "#2F4F4F", "#696969", "#C0C0C0"))(41)

tiff("Rarecurve_xASVs.tiff", width = 12, height = 6, units = 'in', res = 600)
par(mar=c(5.1,4.1,4.1,2.1), oma=c(0,0,0,0))
rarecurve(x = xASVs, col = kols, lwd = 2, las = 1, label = TRUE, step = 10, cex = 0.5)
dev.off()

dsfASVs <- decostand(xASVs, method = "frequency")

```



```{r, echo=TRUE, message=TRUE, warning=TRUE}
print('Total reads from raw OTU table:')
print(sum(rowSums(ASVs)))
print('Total reads from PPE OTU table:')
print(sum(rowSums(xASVs)))
print('Total reads standardized PPE OTU table:')
print(sum(rowSums(rASVs)))
print('Difference in reads between raw and filtered OTU table:')
print(sum(rowSums(ASVs)) - sum(rowSums(xASVs))) #Se redujeron 1244668 ASVs (de 2320653 a (1075985))
print('Difference in reads between filtered and standardized OTU table:')
print(sum(rowSums(xASVs)) - sum(rowSums(rASVs))) #Se redujeron 1045025 ASVs (de 1075985 a 30960)
print('Difference in reads between raw and standardized OTU table:')
print(sum(rowSums(ASVs)) - sum(rowSums(rASVs))) #Se redujeron 2289693 ASVs (de 2320653 a 30960)

#Abundancia relativa
rltv.Otu.Table <- function(x){
x.Data.rltv <- NULL
for (i in 1:dim(x)[1]) {
 x.Data.rltv <- rbind(x.Data.rltv, x[i,]/apply(x, 1, function(x) sum(x))[i])
}
rownames(x.Data.rltv) <- rownames(x)
invisible(x.Data.rltv)
}

rltvASVs <- rltv.Otu.Table(xASVs)
apply(rltvASVs, 2, function(x) sum(x))[1:43]
write.csv2(rltvASVs, file = "C:/Users/Camilo/Desktop/Comparativa/rltvASVs.csv")

rrASVs <- rltv.Otu.Table(rASVs)
apply(rrASVs, 2, function(x) sum(x))[1:43]
write.csv2(rrASVs, file = "C:/Users/Camilo/Dropbox/R/Orion/rrASVs.cvs")

```


```{r, echo=TRUE, message=TRUE, warning=TRUE}
# Tax.Sum.R, funcion para asignar taxonomia a una OTU.Table y juntar los reads de taxa iguales
Tax.sum <- function(OTU.Table, Tax.Table, Tax.lvl ){
  z <- NULL
  y <- NULL
  for (i in 1:length(unique(Tax.Table[colnames(OTU.Table),Tax.lvl]))) {
    if (length(OTU.Table[,which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])])!=length(rownames(OTU.Table))) {
      z <- which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])
      y <- cbind(y, apply(OTU.Table[,which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])], 1, function(x) sum(x)))
    } else { 
      y <- cbind(y, OTU.Table[,which(Tax.Table[colnames(OTU.Table),Tax.lvl]==unique(Tax.Table[colnames(OTU.Table),Tax.lvl])[i])])
    }
  }
  colnames(y) <- unique(Tax.Table[colnames(OTU.Table),Tax.lvl])
  invisible((y))
}

TSDiv <- Tax.sum(xASVs, fTXs, 5) %>% as.data.frame()
write.csv2(TSDiv, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/TSDiv.csv")

tiff("Division_Abundance_PPE.tiff", width = 10, height = 8, units = 'in', res = 600)
print('CLASS DIVISION')
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", legend = colnames(TSDiv), cex = 1.1, ncol = 1, fill = c("#002c3d", "#025a5e", "#137c7c", "#41cc86", "#fee448", "#fcae5a", "#fa776b", "#b11971", "#4e0066"), x.intersp = 0.1, xjust = 0.1, yjust = 0.3, y.intersp = 0.8, bty = "n", adj = 0, text.width = 0.1, pt.cex = 0.1)
par(mar = c(5.1,4.1,4.1,2.1), oma = c(0,0,0,0))
barplot(t(TSDiv), border = NA, ylab = "Sample Size", ylim = c(0,50000), axes = TRUE, col = c("#002c3d", "#025a5e", "#137c7c", "#41cc86", "#fee448", "#fcae5a", "#fa776b", "#b11971", "#4e0066"), las = 2, cex.names = 0.8, cex.axis = 0.9)
dev.off()
```


# Fijarse que la primera columna de la tabla resultante corresponde a los valores NA del df de taxa que fueron tratados como "0" al obtener TSEj. Al realizar analisis posteriores dichos datos obtienen un valor correspondiente por lo que no se suelen considerar dentro de algunas funciones pero estadisticamente si ejercen un efecto apreciable en el análisis de los datos. Esto se puede apreciar claramente cuando vemos que la ausencia de datos dentro de una variable se debe precisamente a dicha variable, por ejemplo, podemos seguir la ASV1, ASV38, ASV45 a lo largo de las clasificaciones taxonómicas. Al igual que el resto de ASVs en la matriz, estas se pueden asignar al rino eukaryota, pero si subimos de nivel, vemos claramente que solo ASV38 y ASV45 pueden asignarse a la clasificación de supergrupo, y no así ASV1, lo cual además condiciona sus clasificaciones consecuentes. Posteriormente vemos como las 2 ASVs restantes se pueden asignar sólo hasta el nivel de división taxonómica mientras que otras ASVs se pueden asignar hasta el nivel de especie.
# Si fuesemos siguiendo las ASVs a lo largo de las asignaciones por niveles esto se vería claramente, además esta idea se refuerza también por el hecho que no existen (por lo menos en este set de datos) asignaciones que se produzcan despues de un valor NA, lo que a su vez nos puede hablar de la robustes de la técnica de asignación. No obstante, no podemos aseverar que la asignación producida haya sido erronea, para lo cual es necesario otro set de datos que tengan un origen similar a nuestras muestras actuales y que se hayan sometidos a procesamientos similares donde la misma secuencia de ASV1 genere la misma clasificación.
# Estos datos ausentes se pueden clasificar como valores "Missing not at random" (MNAR) y estadisticamente no deben ser considerados como faltantes ni atribuirles un valor "0".


```{r, echo=TRUE, message=TRUE, warning=TRUE}
# DF tidy up and management for better visualization
TSEj <- read.csv("E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/TSDiv.csv", header = T, sep = ";", dec = '.', skip = 0) %>% 
  rename(Muestra = X) %>% 
  mutate(Sitio = as.factor(c(rep("Cha", 12), rep("Fla", 12), rep("Hu", 12), rep("Pc", 5))), 
                         .before = "Chlorophyta") %>% 
  gather(key = "Taxa", value = "Abundance", -c(1,2))

ebar <- 1 # Set a number of 'empty bar'
n0bsType <- nlevels(as.factor(TSEj$Taxa))
plus <- data.frame(matrix(NA, ebar*nlevels(TSEj$Sitio)*n0bsType, ncol(TSEj)))
colnames(plus) <- colnames(TSEj)
plus$Sitio <- rep(levels(TSEj$Sitio), each = ebar*n0bsType)
TSEj <- rbind(TSEj, plus)
TSEj <- TSEj %>% arrange(Sitio, Muestra)
TSEj$ID <- rep(seq(1, nrow(TSEj)/n0bsType), each = n0bsType)

# Get the name and the y position of each label
label_data <- TSEj %>% group_by(ID, Muestra) %>% summarize(tot = sum(Abundance))
number_of_bar <- nrow(label_data) # calculate the ANGLE of the labels
angle <-  90 - 360 * (label_data$ID-0.5) /number_of_bar # substract 0.5 to center the names with their respective bars, extreme right=1 and extreme left=0
# calculate the alignment of labels: right or left
label_data$hjust <- ifelse(angle < -90, 1, 0) # If I am on the left part of the plot, my labels have currently an angle < -90
label_data$angle <- ifelse(angle < -90, angle+180, angle) # flip angle BY to make them readable

# prepare a data frame for base lines
base_data <- TSEj %>% 
  group_by(Sitio) %>% 
  summarize(start = min(ID), end = max(ID) - ebar) %>% 
  rowwise() %>% 
  mutate(title = mean(c(start, end)))

# prepare a data frame for grid (scales)
grid_data <- base_data
grid_data$end <- grid_data$end[c(nrow(grid_data), 1:nrow(grid_data)-1)] + 1
grid_data$start <- grid_data$start - 1
grid_data <- grid_data[-1, ]

# Make the plot
circulo <- ggplot(TSEj) +
  # Add the stacked bar
  geom_bar(aes(x = as.factor(ID), y = Abundance, fill = Taxa), stat = "identity", alpha = 0.9) + 
  scale_fill_manual(values = c("Chlorophyta" = "#002c3d", "Ochrophyta" = "#00564e", "Cryptophyta" = "#359548", "Haptophyta" = "#6aab30", "Katablepharidophyta" = "#bacc0c", "Cryptophyta:nucl" = "#acdd3c", "Rhodophyta" = "#83e377", "Stramenopiles_X" = "#16db93", "Alveolata_X" = "#4d194d")) +
  ylim(-20000, max(label_data$tot, na.rm = TRUE)) + 
  theme_minimal() + 
  theme(
    legend.position = "bottom",
    legend.title = element_text(face = "bold"), 
    axis.text = element_blank(),
    axis.title = element_blank(), 
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1, 4), "cm")
  ) + 
  coord_polar() + 
  # Add labels on top of each bar
  geom_text(data = label_data, aes(x = ID, y = tot+1000, label = Muestra, hjust = hjust), color = "black", fontface = "bold", alpha = 0.7, size = 4, angle = label_data$angle, inherit.aes = FALSE) + 
  # Add base line information
  geom_segment(data = base_data, aes(x = start, y = -800, xend = end, yend = -800), colour = "#495057", alpha = 1, size = 1, inherit.aes = FALSE) + 
  geom_text(data = base_data, aes(x = title, y = -3500, label = Sitio), hjust = c(1, 1, 0, 0), colour = "#495057", alpha = 0.6, size = 5, fontface = "bold", inherit.aes = FALSE)

clegend <- get_legend(circulo)
circulo <- circulo + theme(legend.position = "none")
as_ggplot(clegend)

#Save as png
ggsave(circulo, file = "Division_Abundance_PPE_per-site.png", path = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/", width = 20, height = 20, dpi = 600)

```

Con este grafico podemos apreciar (a mi juicio) de forma clara lo que ocurre en las curvas de rarefacción, especialmente con las muestras: S04 (C2A17), S10 (C4A17) y S23 (F4F18). Esto es, la covertura del esfuerzo muestreal para las secuencias de ASV correspondientes a PPE


```{r, echo=TRUE, message=TRUE, warning=TRUE}
#What if we wanted to "see" something similar but instead of taxa Divisions with OTU present at each site
#DO NOT REPLICATE THIS (only if necessary), YOUR PC WILL APPRECIATE IT
CN <- fTXs[, 2]
fASVs <- xASVs #Notice we are not using standardized data for this plots
colnames(fASVs) <- CN
cASVs <- fASVs %>% 
  mutate(Muestra = c("C1_2017-04", "C1_2018-02", "C1_2018-04", "C2_2017-04", "C2_2018-02", "C2_2018-04", "C3_2017-04", "C3_2018-02", "C3_2018-04", "C4_2017-04", "C4_2018-02", "C4_2018-04", "F1_2017-04", "F1_2018-02", "F1_2018-04", "F2_2017-04", "F2_2018-02", "F2_2018-04", "F3_2017-04", "F3_2018-02", "F3_2018-04", "F4_2017-04", "F4_2018-02", "F4_2018-04", "H1_2017-04", "H1_2018-02", "H1_2018-04", "H2_2017-04", "H2_2018-02", "H2_2018-04", "H3_2017-04", "H3_2018-02", "H3_2018-04", "H4_2017-04", "H4_2018-02", "H4_2018-04", "Ho1_2017-04", "Ho1_2018-02", "P1_2018-02", "P1_2018-04", "P2_2018-02", "P3_2018-02", "P4_2018-02"), 
         Sitio = as.factor(c(rep("Cha", 12), rep("Fla", 12), rep("Hu", 12), rep("Ho", 2), rep("Pc", 5))), 
         .before = "ASV1") %>% 
  gather(key = "OTU", value = "Abundance", -c(1,2))

n0bsTypec <- nlevels(as.factor(cASVs$OTU))
plusc <- data.frame(matrix(NA, ebar*nlevels(cASVs$Sitio)*n0bsTypec, ncol(cASVs)))
colnames(plusc) <- colnames(cASVs)
plusc$Sitio <- rep(levels(cASVs$Sitio), each = ebar*n0bsTypec)
cASVs <- rbind(cASVs, plusc)
cASVs <- cASVs %>% arrange(Sitio, Muestra)
cASVs$ID <- rep(seq(1, nrow(cASVs)/n0bsTypec), each = n0bsTypec)

#Label name and 'y' position
label_datac <- cASVs %>% group_by(ID, Muestra) %>% summarize(tot = sum(Abundance))
number_of_barc <- nrow(label_datac)
Angle <-  90 - 360 * (label_datac$ID-0.5) /number_of_barc
label_datac$hjust <- ifelse(Angle < -90, 1, 0)
label_datac$Angle <- ifelse(Angle < -90, Angle+180, Angle)

#Base lines DF
base_datac <- cASVs %>% 
  group_by(Sitio) %>% 
  summarize(Start = min(ID), End = max(ID) - ebar) %>% 
  rowwise() %>% 
  mutate(Title = mean(c(Start, End)))

#Grid DF (not use yet)
grid_datac <- base_datac
grid_datac$End <- grid_datac$End[c(nrow(grid_datac), 1:nrow(grid_datac)-1)] + 1
grid_datac$Start <- grid_datac$Start - 1
grid_datac <- grid_datac[-1, ]

cplot <- ggplot(cASVs) +
  geom_bar(aes(x = as.factor(ID), y = Abundance, fill = OTU), stat = "identity", alpha = 0.9) + 
  #We are now working with 1000+ variables, so it is better to automatically assign the colors
  scale_fill_viridis(discrete = TRUE) +
  ylim(-20000, max(label_datac$tot, na.rm = TRUE)) + 
  theme_minimal() + 
  theme(
    legend.position = "bottom", 
    legend.title = element_text(face = "bold"),
    axis.text = element_blank(),
    axis.title = element_blank(), 
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1, 4), "cm")
  ) + 
  coord_polar() + 
  geom_text(data = label_datac, aes(x = ID, y = tot+1000, label = Muestra, hjust = hjust), color = "black", fontface = "bold", alpha = 0.7, size = 4, angle = label_datac$Angle, inherit.aes = FALSE)+ 
  geom_segment(data = base_datac, aes(x = Start, y = -800, xend = End, yend = -800), colour = "#495057", alpha = 0.9, size = 0.9, inherit.aes = FALSE) + 
  geom_text(data = base_datac, aes(x = Title, y = -3500, label = Sitio), hjust = c(1, 1, 0, 0, 0), colour = "#495057", alpha = 0.6, size = 5, fontface = "bold", inherit.aes = FALSE)

cpltlgnd <- get_legend(cplot)
as_ggplot(cpltlgnd)
cplot <- cplot + theme(legend.position = "none")
cplot

#Save as png
ggsave(cplot, file = "PPE_ASV_Abundance_per-site.png", path = "E:/R/Proyecto_Doctorado/Press/", width = 15, height = 15, dpi = 300)

```


Esto nos da una idea visual de como se distribuyen las ASV de PPE en los sitios de interes/muestreo, no obstante, no entrega información de fácil acceso para explicar algún fenómeno de interes.
*Nota:* Lo mejor es ordenar la asignación de "tags" para facilitar la asignación de colores. Por ejemplo, "ASV_01... ASV_n" permite realizar conjeturas asociadas al espectro de la paleta de colores utilizada.


## Data preparation for UpSetR
```{r, echo=TRUE, message=TRUE, warning=TRUE}
wASVs <- read.csv("E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/xASVs.csv", header = T, sep = ";", dec = '.', skip = 0)
wSN <- wASVs[, 1]
wASVs <- wASVs[, -1]
print(all(colnames(wASVs)%in%rownames(fTXs)))
rownames(wASVs) <- wSN
QN <- fTXs[, 2]
colnames(wASVs) <- QN
wASVs <- data.frame(t(wASVs))
write.csv2(wASVs, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/wASVs.csv")
iwASVs <- wASVs %>%
  mutate(Cha = as.integer(rowSums(wASVs[1:12])),
         Fla = as.integer(rowSums(wASVs[13:24])),
         Hu = as.integer(rowSums(wASVs[25:36])),
         Pc = as.integer(rowSums(wASVs[37:41])),
         .before = "C1_2018.02")
iwASVs <- decostand(iwASVs, method = "pa")
write.csv2(iwASVs, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/iwASVs.csv")
```


##UpSetR
```{r, echo=TRUE, message=TRUE, warning=TRUE}
iwASVs <- read.csv("E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/eTodas/iwASVs.csv", header = TRUE, sep = ";")
tiff("eTodas_UpSetR.tiff", width = 15, height = 9, units = 'in', res = 600)
upset(iwASVs, sets = c("Cha", "Fla", "Hu", "Pc"), 
      keep.order = TRUE,
      query.legend = "top",
      queries = list(list(query = intersects, params = "Cha", color = "#0B525B", active = TRUE, query.name = "Unique Cha ASV"),
                     list(query = intersects, params = "Fla", color = "#02C39A", active = TRUE, query.name = "Unique Fla ASV"),
                     list(query = intersects, params = "Hu", color = "#FFD700", active = TRUE, query.name = "Unique Hu ASV"),
                     list(query = intersects, params = "Pc", color = "#FFA500", active = TRUE, query.name = "Unique Pc ASV"),
                     list(query = intersects, params = list("Cha", "Fla", "Hu", "Pc"), color = "#FF0000", active = TRUE, query.name = "Shared Sites ASV")), 
      point.size = 3, 
      line.size = 1.5, 
      text.scale = 1.6,
      mainbar.y.label = "Sites Intersections", 
      sets.x.label = "ASV per Site")
dev.off()
```


#DF preparation
```{r, echo=TRUE, message=TRUE, warning=TRUE}
yASVs <- read.csv("C:/Users/Camilo/Dropbox/R/Orion/rASVs.csv", header = T, sep = ";", dec = '.', skip = 0)
yASVs <- yASVs[, -1]
print(all(colnames(yASVs)%in%rownames(fTXs)))
colnames(yASVs) <- QN
yASVs <- yASVs %>% 
  mutate(Muestra = c("C1_2017.04", "C1_2018.02", "C1_2018.04", "C2_2017.04", "C2_2018.02", "C2_2018.04", "C3_2017.04", "C3_2018.02", "C3_2018.04", "C4_2017.04", "C4_2018.02", "C4_2018.04", "F1_2017.04", "F1_2018.02", "F1_2018.04", "F2_2017.04", "F2_2018.02", "F2_2018.04", "F3_2017.04", "F3_2018.02", "F3_2018.04", "F4_2017.04", "F4_2018.02", "F4_2018.04", "H1_2017.04", "H1_2018.02", "H1_2018.04", "H2_2017.04", "H2_2018.02", "H2_2018.04", "H3_2017.04", "H3_2018.02", "H3_2018.04", "H4_2017.04", "H4_2018.02", "H4_2018.04", "Ho1_2017.04", "Ho1_2018.02", "P1_2018.02", "P1_2018-04", "P2_2018.02", "P3_2018.02", "P4_2018.02"),
         .before = "ASV_1")
RN <- yASVs[, 1]
yASVs <- yASVs[, -1]
rownames(yASVs) <- RN
yASVs <- data.frame(t(yASVs))
yASVs <- yASVs %>%
  mutate(Cha = as.integer(rowSums(yASVs[1:12])),
         Fla = as.integer(rowSums(yASVs[13:24])),
         Hu = as.integer(rowSums(yASVs[25:36])),
         Ho = as.integer(rowSums(yASVs[37:38])),
         Pc = as.integer(rowSums(yASVs[39:43])),
         .before = "C1_2017.04")
yASVs[yASVs>0] <- 1
write.csv2(yASVs, file = "C:/Users/Camilo/Dropbox/R/Orion/AP_yASVs.csv")

```


```{r, echo=TRUE, message=TRUE, warning=TRUE}
APyASVs <- read.csv("C:/Users/Camilo/Dropbox/R/Orion/AP_yASVs.csv", header = TRUE, sep = ";")
tiff("UpSetR_standardized_filtered-Div_ASV.tiff", width = 21, height = 11, units = 'in', res = 300)
upset(APyASVs, sets = c("Cha", "Fla", "Hu", "Ho", "Pc"), 
      keep.order = TRUE,
      query.legend = "top",
      queries = list(list(query = intersects, params = "Cha", color = "#05668D", active = TRUE, query.name = "Unique Cha ASV"),
                     list(query = intersects, params = "Fla", color = "#028090", active = TRUE, query.name = "Unique Fla ASV"),
                     list(query = intersects, params = "Hu", color = "#00A896", active = TRUE, query.name = "Unique Hu ASV"),
                     list(query = intersects, params = "Ho", color = "#02C39A", active = TRUE, query.name = "Unique Ho ASV"),
                     list(query = intersects, params = "Pc", color = "#7ADC4D", active = TRUE, query.name = "Unique Pc ASV"),
                     list(query = intersects, params = list("Cha", "Fla", "Hu", "Ho", "Pc"), color = "#FDB017", active = TRUE, query.name = "Shared Sites ASV")), 
      point.size = 3, 
      line.size = 1.5, 
      text.scale = 1.6,
      mainbar.y.label = "Sites Intersections", 
      sets.x.label = "ASV per Site")
dev.off()
```


#DF preparation
```{r, echo=TRUE, message=TRUE, warning=TRUE}
Feb.ASVs <- read.csv("C:/Users/Camilo/Desktop/Comparativa/xASVs.csv", header = T, sep = ";", dec = '.', skip = 0)
Feb.ASVs <- Feb.ASVs[, -1]
print(all(colnames(Feb.ASVs)%in%rownames(fTXs))) #If TRUE you can continue
FebN <- fTXs[, 2] #Extract OTU names (ID) from Div-filtered taxa assigned DF (fTXs)
colnames(Feb.ASVs) <- FebN #Assign sequences their proper ID
#Add fitted identification for samples(ID + date to easily identify them later)
Feb.ASVs <- Feb.ASVs %>% 
  mutate(Muestra = c("C1_2017.04", "C1_2018.02", "C1_2018.04", "C2_2017.04", "C2_2018.02", "C2_2018.04", "C3_2017.04", "C3_2018.02", "C3_2018.04", "C4_2017.04", "C4_2018.02", "C4_2018.04", "F1_2017.04", "F1_2018.02", "F1_2018.04", "F2_2017.04", "F2_2018.02", "F2_2018.04", "F3_2017.04", "F3_2018.02", "F3_2018.04", "F4_2017.04", "F4_2018.02", "F4_2018.04", "H1_2017.04", "H1_2018.02", "H1_2018.04", "H2_2017.04", "H2_2018.02", "H2_2018.04", "H3_2017.04", "H3_2018.02", "H3_2018.04", "H4_2017.04", "H4_2018.02", "H4_2018.04", "Ho1_2017.04", "Ho1_2018.02", "P1_2018.02", "P1_2018-04", "P2_2018.02", "P3_2018.02", "P4_2018.02"),
         .before = "ASV_1")
RN <- Feb.ASVs[, 1]
Feb.ASVs <- Feb.ASVs[, -1]
rownames(Feb.ASVs) <- RN
Feb.ASVs <- data.frame(t(Feb.ASVs)) #Transpose DF and keep it format
write.csv2(Feb.ASVs, file = "C:/Users/Camilo/Desktop/Comparativa/iASVs.csv")
Feb.ASVs <- Feb.ASVs %>% 
  select(C1_2018.02, C2_2018.02, C3_2018.02, C4_2018.02, F1_2018.02, F2_2018.02, F3_2018.02, F4_2018.02, H1_2018.02, H2_2018.02, H3_2018.02, H4_2018.02, Ho1_2018.02, P1_2018.02, P2_2018.02, P3_2018.02, P4_2018.02) %>% 
  mutate(Cha = as.integer(rowSums(Feb.ASVs[1:4])),
         Fla = as.integer(rowSums(Feb.ASVs[5:8])),
         Hu = as.integer(rowSums(Feb.ASVs[9:12])),
         Ho = as.integer(Ho1_2018.02),
         Pc = as.integer(rowSums(Feb.ASVs[14:17])),
         .before = "C1_2018.02")
write.csv2(Feb.ASVs, file = "C:/Users/Camilo/Desktop/Comparativa/FebASVs.csv")

#Transform data into a binary DF (presence/absence)
Feb.ASVs <- decostand(Feb.ASVs, method = "pa") #you can choose
write.csv2(Feb.ASVs, file = "C:/Users/Camilo/Desktop/Comparativa/AP_FebASVs.csv")

```


```{r, echo=TRUE, message=TRUE, warning=TRUE}
APFASVs <- read.csv("C:/Users/Camilo/Desktop/Comparativa/AP_FebASVs.csv", header = TRUE, sep = ";")
tiff("February_UpSetR.tiff", width = 21, height = 11, units = 'in', res = 300)
upset(APFASVs, sets = c("Cha", "Fla", "Hu", "Ho", "Pc"), 
      keep.order = TRUE,
      query.legend = "top",
      queries = list(list(query = intersects, params = "Cha", color = "#40515D", active = TRUE, query.name = "Unique Cha ASV"),
                     list(query = intersects, params = "Fla", color = "#96E2D9", active = TRUE, query.name = "Unique Fla ASV"),
                     list(query = intersects, params = "Hu", color = "#2EC4B6", active = TRUE, query.name = "Unique Hu ASV"),
                     list(query = intersects, params = "Ho", color = "#FF9F1C", active = TRUE, query.name = "Unique Ho ASV"),
                     list(query = intersects, params = "Pc", color = "#BACC0C", active = TRUE, query.name = "Unique Pc ASV"),
                     list(query = intersects, params = list("Cha", "Fla", "Hu", "Ho", "Pc"), color = "#E71D36", active = TRUE, query.name = "Shared Sites ASV")), 
      point.size = 3, 
      line.size = 1.5, 
      text.scale = 1.6,
      mainbar.y.label = "Sites Intersections", 
      sets.x.label = "ASV per Site")
dev.off()
```

Vemos que al analizar los datos pertenecientes a Febrero de 2018 existen más ASVs únicas en Punta de Choros (172) que en otros sitios, incluso superando el número de ASVs únicas (101) al juntar todos los periodos de muestreo. Esto se puede atribuir, a una disminución de OTUs en otros sitios o efectivamente a un aumento de estas en Punta de Choros. Debido a la naturaleza de nuestros datos y trabajos encontramos en la literatura podríamos atribuir esta diferencia a la estacionalidad, sin embargo, debemos considerar que altas concentraciones de metales pesados como el Cu y el Fe pueden inducir cambios en la respuesta de estos microoranismos respecto a factores abioticos estacionales (desacople de patrones bióticos y abióticos estacionales; Glasner et al., 2021).


```{r, echo=TRUE, message=TRUE, warning=TRUE}
rFASVs <- read.csv("C:/Users/Camilo/Dropbox/R/Orion/rASVs.csv", header = T, sep = ";", dec = '.', skip = 0)
rFASVs <- rFASVs[, -1]
print(all(colnames(rFASVs)%in%rownames(fTXs))) #If TRUE you can continue
rFN <- fTXs[, 2] #Extract OTU names (ID) from Div-filtered taxa assigned DF (fTXs)
colnames(rFASVs) <- rFN #Assign sequences their proper ID
#Add fitted identification for samples(ID + date to easily identify them later)
rFASVs <- rFASVs %>% 
  mutate(Muestra = c("C1_2017.04", "C1_2018.02", "C1_2018.04", "C2_2017.04", "C2_2018.02", "C2_2018.04", "C3_2017.04", "C3_2018.02", "C3_2018.04", "C4_2017.04", "C4_2018.02", "C4_2018.04", "F1_2017.04", "F1_2018.02", "F1_2018.04", "F2_2017.04", "F2_2018.02", "F2_2018.04", "F3_2017.04", "F3_2018.02", "F3_2018.04", "F4_2017.04", "F4_2018.02", "F4_2018.04", "H1_2017.04", "H1_2018.02", "H1_2018.04", "H2_2017.04", "H2_2018.02", "H2_2018.04", "H3_2017.04", "H3_2018.02", "H3_2018.04", "H4_2017.04", "H4_2018.02", "H4_2018.04", "Ho1_2017.04", "Ho1_2018.02", "P1_2018.02", "P1_2018-04", "P2_2018.02", "P3_2018.02", "P4_2018.02"),
         .before = "ASV_1")
rRN <- rFASVs[, 1]
rFASVs <- rFASVs[, -1]
rownames(rFASVs) <- rRN
rFASVs <- data.frame(t(rFASVs)) #Transpose DF and keep it format
write.csv2(rFASVs, file = "C:/Users/Camilo/Dropbox/R/Orion/riASVs.csv")
rFASVs <- rFASVs %>% 
  select(C1_2018.02, C2_2018.02, C3_2018.02, C4_2018.02, F1_2018.02, F2_2018.02, F3_2018.02, F4_2018.02, H1_2018.02, H2_2018.02, H3_2018.02, H4_2018.02, Ho1_2018.02, P1_2018.02, P2_2018.02, P3_2018.02, P4_2018.02) %>% 
  mutate(Cha = as.integer(rowSums(rFASVs[1:4])), 
         Fla = as.integer(rowSums(rFASVs[5:8])), 
         Hu = as.integer(rowSums(rFASVs[9:12])), 
         Ho = as.integer(Ho1_2018.02), 
         Pc = as.integer(rowSums(rFASVs[14:17])), 
         .before = "C1_2018.02")
write.csv2(rFASVs, file = "C:/Users/Camilo/Dropbox/R/Orion/rFASVs.csv")

#Transform data into a binary DF (presence/absence)
rFASVs[rFASVs>0] <- 1
rFASVs <- decostand(rFASVs, method = "pa")
write.csv2(rFASVs, file = "C:/Users/Camilo/Dropbox/R/Orion/AP_rFASVs.csv")

```


```{r, echo=TRUE, message=TRUE, warning=TRUE}
APrFASVs <- read.csv("C:/Users/Camilo/Dropbox/R/Orion/AP_rFASVs.csv", header = TRUE, sep = ";")
tiff("February_Standardized_UpSetR.tiff", width = 21, height = 11, units = 'in', res = 300)
upset(APrFASVs, sets = c("Cha", "Fla", "Hu", "Ho", "Pc"), 
      keep.order = TRUE,
      query.legend = "top",
      queries = list(list(query = intersects, params = "Cha", color = "#40515D", active = TRUE, query.name = "Unique Cha ASV"),
                     list(query = intersects, params = "Fla", color = "#96E2D9", active = TRUE, query.name = "Unique Fla ASV"),
                     list(query = intersects, params = "Hu", color = "#2EC4B6", active = TRUE, query.name = "Unique Hu ASV"),
                     list(query = intersects, params = "Ho", color = "#FF9F1C", active = TRUE, query.name = "Unique Ho ASV"),
                     list(query = intersects, params = "Pc", color = "#BACC0C", active = TRUE, query.name = "Unique Pc ASV"),
                     list(query = intersects, params = list("Cha", "Fla", "Hu", "Ho", "Pc"), color = "#E71D36", active = TRUE, query.name = "Shared Sites ASV")), 
      point.size = 3, 
      line.size = 1.5, 
      text.scale = 1.6,
      mainbar.y.label = "Sites Intersections", 
      sets.x.label = "ASV per Site")
dev.off()
```


Podemos hablar de cambios en la capacidad de irritabilidad de estos microorganismos? [**Kilgour, 1987**](https://link.springer.com/chapter/10.1007/978-1-349-09692-3_13)

Revisemos (tratemos) de ver cuales son las ASVs que se pueden apreciar en Febrero de 2018 que no se aprecian al considerar todas las muestras. Para esto tomaremos como referencia Punta de Choros.


```{r, echo=TRUE, message=TRUE, warning=TRUE}
FHu <- read.csv("C:/Users/Camilo/Desktop/Comparativa/AP_FebASVs.csv", header = TRUE, sep = ";") %>% rename(OTU = X)
rownames(FHu) <- FHu[,1]
FHu <- FHu %>% filter(Hu == 1) %>% filter(Cha == 0) %>% filter(Fla == 0) %>% filter(Ho == 0) %>% filter(Pc == 0) #You can do this filtering with a condition, its better and simpler that way
HuFilt <- rownames(FHu) #These are the 172 ASVs that are exclusively present on Pc according to the UpSetR data
HufTXs <- fTXs %>% filter(OTU %in% HuFilt)
HuSN <- HufTXs[, 1]
HuASVs <- select(xASVs, all_of(HuSN)) #DF with selected PPE Divisions' ASV across all samples 
HuTSDiv <- Tax.sum(HuASVs, HufTXs, 5) %>% as.data.frame() #Ojo con esto
gencols <- colorRampPalette(c("#3c1642", "#086375", "#1dd3b0", "#affc41", "#b2ff9e"))(5)

HuTSDiv <- Tax.sum(HuASVs, HufTXs, 5) %>% as.data.frame()

tiff("Feb_Unique_Hu_ASV_Division_Abundance.tiff", width = 12, height = 6, units = 'in', res = 600)
print('CLASS DIVISION')
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", legend = colnames(HuTSDiv), cex = 1.1, ncol = 1, fill = gencols, x.intersp = 0.3, xjust = 0.3, yjust = 0.3, y.intersp = 0.8, bty = "n", adj = 0, text.width = 0.3, pt.cex = 0.3)
par(mar = c(5.1,4.1,4.1,2.1), oma = c(0,0,0,0))
barplot(t(HuTSDiv), border = NA, xlab = "Samples", ylab = "Sample Size", ylim = c(0,1000), axes = TRUE, col = gencols, las = 2, cex.names = 0.6)
dev.off()

```

##Let's do it but with standardized data (rarefacted)
```{r, echo=TRUE, message=TRUE, warning=TRUE}
rFHu <- read.csv("/Users/Artemis/Dropbox/R/Press/AP_rFASVs.csv", header = TRUE, sep = ";") %>% rename(OTU = X)
rownames(rFHu) <- rFHu[,1]
rFHu <- rFHu %>% filter(Hu == 1 & Cha == 0 & Fla == 0 & Ho == 0 & Pc == 0) #You can do this filtering with a condition, its better and simpler that way
rHuFilt <- rownames(rFHu) #These are the 172 ASVs that are exclusively present on Pc according to the UpSetR data
rHufTXs <- fTXs %>% filter(OTU %in% rHuFilt)
rHuSN <- rHufTXs[, 1]
rHuASVs <- select(rASVs, all_of(rHuSN)) #DF with selected PPE Divisions' ASV across all samples

rHuTSDiv <- Tax.sum(rHuASVs, rHufTXs, 5) %>% as.data.frame()
names(HuTSClass)[14] <- "Zeros"
HuTSClass <- HuTSClass[,!grepl("Zeros", names(HuTSClass))]
gencols <- colorRampPalette(c("#3c1642", "#086375", "#1dd3b0", "#affc41", "#b2ff9e"))(5)

tiff("Feb_Unique_Hu_rASV_Abundance_Division.tiff", width = 12, height = 6, units = 'in', res = 600)
print('CLASS DIVISION')
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", legend = colnames(rHuTSDiv), cex = 1.1, ncol = 3, fill = gencols, x.intersp = 0.3, xjust = 0.3, yjust = 0.3, y.intersp = 0.8, bty = "n", adj = 0, text.width = 0.3, pt.cex = 0.3)
par(mar = c(5.1,4.1,4.1,2.1), oma = c(0,0,0,0))
barplot(t(rHuTSDiv), border = NA, xlab = "Samples", ylab = "Sample Size", ylim = c(0,100), axes = TRUE, col = gencols, las = 2, cex.names = 0.6)
dev.off()

```


```{r, echo=TRUE, message=TRUE, warning=TRUE}
HuTSDiv <- data.frame(t(HuTSDiv))
dsHuTSDiv <- decostand(HuTSDiv, method = "chi.square", MARGIN = 1)
dsHuTSDiv <- data.frame(t(dsHuTSDiv))

tiff("decostand.tiff", width = 12, height = 6, units = 'in', res = 600)
print('CLASS DIVISION')
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", legend = colnames(dsHuTSDiv), cex = 1.1, ncol = 3, fill = gencols, x.intersp = 0.3, xjust = 0.3, yjust = 0.3, y.intersp = 0.8, bty = "n", adj = 0, text.width = 0.3, pt.cex = 0.3)
par(mar = c(5.1,4.1,4.1,2.1), oma = c(0,0,0,0))
barplot(t(dsHuTSDiv), border = NA, xlab = "Samples", ylab = "Sample Size", ylim = c(0,2), axes = TRUE, col = gencols, las = 2, cex.names = 0.6)
dev.off()

```




























```{r, echo=TRUE, message=TRUE, warning=TRUE}
FPc <- read.csv("/Users/Artemis/Dropbox/R/Press/AP_FebASVs.csv", header = TRUE, sep = ";") %>% rename(OTU = X)
rownames(FPc) <- FPc[,1]
FPc <- FPc %>% select(OTU, Cha, Fla, Hu, Ho, Pc) %>% filter(Pc == 1) %>% filter(Cha == 0) %>% filter(Fla == 0) %>% filter(Hu == 0) %>% filter(Ho == 0) #You can do this filtering with a condition, its better and simpler that way
fltr <- rownames(FPc) #These are the 172 ASVs that are exclusively present on Pc according to the UpSetR data
#Filter these ASVs from complete data and check if there are differences
APc <- read.csv("/Users/Artemis/Dropbox/R/Press/AP_wASVs.csv", header = TRUE, sep = ";") %>% rename(OTU = X) 
rownames(APc) <- APc[,1]
fAPc <- subset(APc, !OTU %in% fltr) #Successfully filtered the ASVs that are exclusively present on Pc on Feb/2018
fAPc.P <- fAPc %>% filter(Pc == 1) %>% filter(Cha == 0) %>% filter(Fla == 0) %>% filter(Hu == 0) %>% filter(Ho == 0) #From the remaining data we see that only one ASV (ASV_4000) is exclusively present at Pc in August/2018 (P1)
fTXs <- read.csv("/Users/Artemis/Dropbox/R/Press/fTXs.csv", header = TRUE, sep = ";")
fTXs <- fTXs[, -1]
rownames(fTXs) <- fTXs[, 2]
filter(fTXs, OTU == "ASV_4000") #ASV assigned to an organisms from the Florenciellales family (may be related to Pseudochattonella verruculosa, organism associated with salmon mortalities to the south of Chile)

#What about the ASVs present exclusively on Pc at February/2018?
FfTXs <- subset(fTXs, OTU %in% fltr)
Genus <- unique(FfTXs[, 9]) #This give us a list with the different Genus identified in the previous 172 ASVs of interest (yo can set it to whichever assignation you prefer)

nASVs <- read.csv("/Users/Artemis/Dropbox/R/Press/nASVs.csv", header = TRUE, sep = ";") %>% subset(X %in% fltr)
nombre <- nASVs[, 1]
nASVs <- nASVs[, -1]
rownames(nASVs) <- nombre
nASVs <- data.frame(t(nASVs))
nTSGen <- Tax.sum(nASVs, FfTXs, 10) %>% as.data.frame()
names(nTSGen)[4] <- "Zeros"
nTSGen <- nTSGen[,!grepl("Zeros", names(nTSGen))]
gencols <- viridis(79)

tiff("Feb_Unique_Pc_ASV_Abundance.tiff", width = 12, height = 6, units = 'in', res = 600)
print('CLASS GENUS')
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", legend = colnames(nTSGen), cex = 1.1, ncol = 3, fill = gencols, x.intersp = 0.3, xjust = 0.3, yjust = 0.3, y.intersp = 0.8, bty = "n", adj = 0, text.width = 0.3, pt.cex = 0.3)
par(mar = c(5.1,4.1,4.1,2.1), oma = c(0,0,0,0))
barplot(t(nTSGen), border = NA, xlab = "Samples", ylab = "Sample Size", ylim = c(0,15000), axes = TRUE, col = gencols, las = 2, cex.names = 0.6)
dev.off()

```


```{r, echo=TRUE, message=TRUE, warning=TRUE}
rFPc <- read.csv("/Users/Artemis/Dropbox/R/Press/AP_rFASVs.csv", header = TRUE, sep = ";") %>% rename(OTU = X)
rownames(rFPc) <- rFPc[,1]
rFPc <- rFPc %>% select(OTU, Cha, Fla, Hu, Ho, Pc) %>% filter(Pc == 1) %>% filter(Cha == 0) %>% filter(Fla == 0) %>% filter(Hu == 0) %>% filter(Ho == 0) #You can do this filtering with a condition, its better and simpler that way
rfltr <- rownames(rFPc) #These are the 172 ASVs that are exclusively present on Pc according to the UpSetR data
#Filter these ASVs from complete data and check if there are differences
rAPc <- read.csv("/Users/Artemis/Dropbox/R/Press/AP_yASVs.csv", header = TRUE, sep = ";") %>% rename(OTU = X) 
rownames(rAPc) <- rAPc[,1]
frAPc <- subset(rAPc, !OTU %in% rfltr) #Successfully filtered the ASVs that are exclusively present on Pc on Feb/2018
frAPc.P <- frAPc %>% filter(Pc == 1) %>% filter(Cha == 0) %>% filter(Fla == 0) %>% filter(Hu == 0) %>% filter(Ho == 0) #From the remaining data we see that only one ASV (ASV_4000) is exclusively present at Pc in August/2018 (P1)
fTXs <- read.csv("/Users/Artemis/Dropbox/R/Press/fTXs.csv", header = TRUE, sep = ";")
fTXs <- fTXs[, -1]
rownames(fTXs) <- fTXs[, 2]
filter(fTXs, OTU == "ASV_4000") #ASV assigned to an organisms from the Florenciellales family (may be related to Pseudochattonella verruculosa, organism associated with salmon mortalities to the south of Chile)

#What about the ASVs present exclusively on Pc at February/2018?
FfTXs <- subset(fTXs, OTU %in% fltr)
Genus <- unique(FfTXs[, 9]) #This give us a list with the different Genus identified in the previous 172 ASVs of interest (yo can set it to whichever assignation you prefer)

nASVs <- read.csv("/Users/Artemis/Dropbox/R/Press/nASVs.csv", header = TRUE, sep = ";") %>% subset(X %in% fltr)
nombre <- nASVs[, 1]
nASVs <- nASVs[, -1]
rownames(nASVs) <- nombre
nASVs <- data.frame(t(nASVs))
nTSGen <- Tax.sum(nASVs, FfTXs, 10) %>% as.data.frame()
names(nTSGen)[4] <- "Zeros"
nTSGen <- nTSGen[,!grepl("Zeros", names(nTSGen))]
gencols <- viridis(79)

tiff("Feb_Unique_Pc_ASV_Abundance.tiff", width = 12, height = 6, units = 'in', res = 600)
print('CLASS GENUS')
plot.new()
par(mar = c(0,0,0,0), oma = c(0,0,0,0))
legend("center", legend = colnames(nTSGen), cex = 1.1, ncol = 3, fill = gencols, x.intersp = 0.3, xjust = 0.3, yjust = 0.3, y.intersp = 0.8, bty = "n", adj = 0, text.width = 0.3, pt.cex = 0.3)
par(mar = c(5.1,4.1,4.1,2.1), oma = c(0,0,0,0))
barplot(t(nTSGen), border = NA, xlab = "Samples", ylab = "Sample Size", ylim = c(0,15000), axes = TRUE, col = gencols, las = 2, cex.names = 0.6)
dev.off()

```

######################################################################################




















































## PCA sin filtro de muestras y secuencias
```{r, echo=TRUE, message=TRUE, warning=TRUE}
TSiR <- Tax.sum(ASV.Tdsi.Rltv, TX.All, 6) %>% as.data.frame()
names(TSiR)[22] <- "NA"
TSiR <- TSiR[,!grepl("NA", names(TSiR))]
write.csv2(TSiR, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/Analisis/Todas/relab_taxa_all.csv")

pca <- rda(TSiR, scale = TRUE)
pca
summary(pca)
ordiplot(pca, type = "text")

PCAsig <- PCAsignificance(pca)
PCAsig
ordiplot(pca, choices = c(2,3), type = "text")

pca_fort <- fortify(pca, axes = 1:2)
pca_fort

ggplot() + 
  geom_point(data = subset(pca_fort, Score == 'sites'),
             mapping = aes(x = PC1, y = PC2),
             colour = "#FF6B6B",
             alpha = 0.5) +
  geom_segment(data = subset(pca_fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(length = unit(0.02, "npc"),
                             type = "open"),
               colour = "#297F87",
               size = 0.5) + 
  geom_text(data = subset(pca_fort, Score == 'species'), # crudely push label away
            mapping = aes(label = Label, x = PC1 * 1.2, y = PC2 * 1.2)) + 
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", sized = 0.7, colour = "darkgray") + 
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.7, colour = "darkgray") + 
  xlab("PC1 (17.78%)") + 
  ylab("PC2 (8.42%)") + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  expand_limits(x = c(-2, 4), y = c(-5, 3))
#Conviene hacerlo con el mayor nivel posible probablemente
```

## PCA con filtro de muestras y secuencias
```{r, echo=TRUE, message=TRUE, warning=TRUE}
TSMPRltv <- Tax.sum(ASV.MPAll.Rltv, TX.Tds, 6) %>% as.data.frame()
names(TSMPRltv)[21] <- "NA"
TSMPRltv <- TSMPRltv[,!grepl("NA", names(TSMPRltv))]
write.csv2(TSMPRltv, file = "E:/R/Proyecto_Doctorado/Objetivo_1/Nuevo_Orden/Analisis/Todas/relab_taxa_mpall.csv")

pcaMP <- rda(TSMPRltv, scale = TRUE)
pcaMP
summary(pcaMP)
ordiplot(pcaMP, type = "text")

PCAMPSig <- PCAsignificance(pcaMP)
PCAMPSig
ordiplot(pcaMP, choices = c(1,2), type = "text")

# To have even more control use the "fortify" function
pcaMP_fort <- fortify(pcaMP, axes = 1:2)
pcaMP_fort

ggplot() + 
  geom_point(data = subset(pcaMP_fort, Score == 'sites'),
             mapping = aes(x = PC1, y = PC2),
             colour = "#FF6B6B",
             alpha = 0.5) +
  geom_segment(data = subset(pcaMP_fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(length = unit(0.02, "npc"),
                             type = "open"),
               colour = "#297F87",
               size = 0.5) + 
  geom_text(data = subset(pcaMP_fort, Score == 'species'), # crudely push label away
            mapping = aes(label = Label, x = PC1 * 1.2, y = PC2 * 1.2)) + 
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.7, colour = "darkgray") + 
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.7, colour = "darkgray") + 
  xlab("PC1 (11.77%)") + 
  ylab("PC2 (10.13%)") + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  expand_limits(x = c(-2, 5), y = c(-3, 5))
```


## Data transformation
Occasionally, the variables in a "raw" data set have properties that violate an assumption of a statistical procedure (e.g. normally distributed values) or which cannot be compared to other variables due to differences in scale or variability. For example, principal components analysis (PCA) *requires that variables be linearly related to one another and on roughly the same scale or will perform poorly*. Rather than abandoning an analysis due to inappropriate data structure, it may be possible to transform the variables so they satisfy the conditions in question. A transformation involves the *application of a mathematical procedure to every value of a given variable or set of variables to create a new set of values*. The new values of the transformed variables should still represent the data, but will be more amenable to analysis or comparison. 

### Ecologically motivated transformations 
These transformations are closely related to several *(dis)similarity and distance measures* and have their collective basis in ecological theory. These transformations may be applied prior to analyses such as principal components analysis (PCA) or redundancy analysis (RDA) of, for example, abundance data. These analyses use simple *Euclidean distances in their ordinations which are often not appropriate for count data*. Hence, these transformations may improve the effectiveness of many analyses in representing ecological relationships. Formulae, further explanation, and examples are available in: Legendre P, Gallagher ED (2001) Ecologically meaningful transformations for ordination of species data. Oecologia. 129(2): 271-280.
*Hellinger:* Particularly suited to *species abundance data*, this transformation gives low weights to variables with low counts and many zeros. The transformation itself comprises dividing each value in a data matrix by its row sum, and taking the square root of the quotient.


## PCA with Hellinger transformation values (data w/o filter)
```{r, echo=TRUE, message=TRUE, warning=TRUE}
TS.hel <- decostand(TSiR, method = "hellinger")
pca.hel <- rda(TS.hel, scale = TRUE)
pca.hel
summary(pca.hel)
ordiplot(pca.hel, type = "text")

PCAHS <- PCAsignificance(pca.hel)
PCAHS
ordiplot(pca.hel, choices = c(1,2), type = "text") #Quizás es notable que los PCA se mantuvieron, pero la ordenacion de los datos en si cambio

pca.hel.fort <- fortify(pca.hel, axes = 1:2)

ggplot() + 
  geom_point(data = subset(pca.hel.fort, Score == 'sites'),
             mapping = aes(x = PC1, y = PC2),
             colour = "#3E978B",
             alpha = 0.5) +
  geom_segment(data = subset(pca.hel.fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(length = unit(0.02, "npc"),
                             type = "open"),
               colour = "#480032",
               size = 0.5) + 
  geom_text(data = subset(pca.hel.fort, Score == 'species'), # crudely push label away
            mapping = aes(label = Label, x = PC1 * 1.2, y = PC2 * 1.2)) + 
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 1, colour = "darkgray") + 
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.7, colour = "darkgray") + 
  xlab("PC1 (16.65%)") + 
  ylab("PC2 (9.36%)") + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  expand_limits(x = c(-2, 9), y = c(-4, 6))
```


## PCA with Hellinger transformation values (data w filter)
```{r, echo=TRUE, message=TRUE, warning=TRUE}
TSMPR.hel <- decostand(TSMPRltv, method = "hellinger")
pcaMP.hel <- rda(TSMPR.hel, scale = TRUE)
pcaMP.hel
summary(pcaMP.hel)
ordiplot(pcaMP.hel, type = "text")

PCAMPR.HS <- PCAsignificance(pcaMP.hel) 
PCAMPR.HS
ordiplot(pcaMP.hel, choices = c(1,2), type = "text")

PCAMPRH.fort <- fortify(pcaMP.hel, axes = 1:2)
ggplot() + 
  geom_point(data = subset(PCAMPRH.fort, Score == 'sites'),
             mapping = aes(x = PC1, y = PC2),
             colour = "#FF0000",
             alpha = 0.5) +
  geom_segment(data = subset(PCAMPRH.fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = PC1, yend = PC2),
               arrow = arrow(length = unit(0.02, "npc"),
                             type = "open"),
               colour = "#480032",
               size = 0.5) + 
  geom_text(data = subset(PCAMPRH.fort, Score == 'species'), # crudely push label away
            mapping = aes(label = Label, x = PC1 * 1.2, y = PC2 * 1.2)) + 
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 1, colour = "darkgray") + 
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.7, colour = "darkgray") + 
  xlab("PC1 (13.84%)") + 
  ylab("PC2 (12.12%)") + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) + 
  expand_limits(x = c(-4, 5), y = c(-4, 5))
```


## NMDS w/o filt
```{r, echo=TRUE, message=TRUE, warning=TRUE}
nmds1 <- metaMDS(TS.hel, autotransform = FALSE)
summary(nmds1)
ordiplot(nmds1, type = "text")
autoplot(nmds1)

#full control with fortified ordination output
NMDS_fort <- fortify(nmds1)
ggplot() +
  geom_point(data = subset(NMDS_fort, Score == 'sites'),
             mapping = aes(x= NMDS1, y = NMDS2),
             colour = "black",
             alpha = 0.5) +
  geom_segment(data = subset(NMDS_fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.015, "npc"),
                             type = "closed"),
               colour = "darkgray", 
               size = 0.8) +
  geom_text(data = subset(NMDS_fort, Score == 'species'), #crudely push labels away
            mapping = aes(label = Label, x = NMDS1 * 1.2, y = NMDS2 * 1.2)) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.8, colour = "gray") +
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.8, colour = "gray") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) +
  expand_limits(x = c(-2, 2), y = c(-2, 3))
```


### Make a two panel plot to reduce complexity
```{r, echo=TRUE, message=FALSE, warning=FALSE, include=FALSE}
p1 <- ggplot() +
  geom_point(data = subset(NMDS_fort, Score == 'sites'),
             mapping = aes(x = NMDS1, y = NMDS2),
             colour = "black",
             alpha = 0.5) +
  geom_segment(data = subset(NMDS_fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.015, "npc"),
                             type = "closed"),
               colour = "darkgray",
               size = 0,
               alpha = 0) +
  geom_text(data = subset(NMDS_fort, Score == 'species'),
            mapping = aes(label = Label, x = NMDS1 * 1.2, y = NMDS2 * 1.2),
            alpha = 0) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.8, colour = "gray") +
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.8, colour = "gray") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"))

p2 <- ggplot() +
  geom_point(data = subset(NMDS_fort, Score == 'sites'),
             mapping = aes(x = NMDS1, y = NMDS2),
             colour = "black",
             alpha = 0) +
  geom_segment(data = subset(NMDS_fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.015, "npc"),
                             type = "closed"),
               colour = "darkgray",
               size = 0.8) +
  geom_text(data = subset(NMDS_fort, Score == 'species'),
            mapping = aes(label = Label, x = NMDS1 * 1.1, y = NMDS2 * 1.1)) + 
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.8, colour = "gray") +
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.8, colour = "gray") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"))

#create a multi-panel plot with one column
ggarrange(p1, p2, ncol = 1)
```


## NMDS w filt
```{r, echo=TRUE, message=TRUE, warning=TRUE}
nmds.mpr <- metaMDS(TSMPR.hel, autotransform = FALSE)
summary(nmds.mpr)
ordiplot(nmds.mpr, type = "text")
autoplot(nmds.mpr)

#full control with fortified ordination output
NMDS.MPRfort <- fortify(nmds.mpr)
ggplot() +
  geom_point(data = subset(NMDS.MPRfort, Score == 'sites'),
             mapping = aes(x= NMDS1, y = NMDS2),
             colour = "black",
             alpha = 0.5) +
  geom_segment(data = subset(NMDS.MPRfort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.015, "npc"),
                             type = "closed"),
               colour = "darkgray", 
               size = 0.8) +
  geom_text(data = subset(NMDS.MPRfort, Score == 'species'), #crudely push labels away
            mapping = aes(label = Label, x = NMDS1 * 1.2, y = NMDS2 * 1.2)) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.8, colour = "gray") +
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.8, colour = "gray") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black")) +
  expand_limits(x = c(-2, 1), y = c(-2, 1))
```


### Two panel plot NMDS filt data transformed
```{r, echo=TRUE, message=FALSE, warning=FALSE, include=FALSE}
MPRH1 <- ggplot() +
  geom_point(data = subset(NMDS.MPRfort, Score == 'sites'),
             mapping = aes(x = NMDS1, y = NMDS2),
             colour = "black",
             alpha = 0.5) +
  geom_segment(data = subset(NMDS.MPRfort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.015, "npc"),
                             type = "closed"),
               colour = "darkgray",
               size = 0,
               alpha = 0) +
  geom_text(data = subset(NMDS.MPRfort, Score == 'species'),
            mapping = aes(label = Label, x = NMDS1 * 1.2, y = NMDS2 * 1.2),
            alpha = 0) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.8, colour = "gray") +
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.8, colour = "gray") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"))

MPRH2 <- ggplot() +
  geom_point(data = subset(NMDS.MPRfort, Score == 'sites'),
             mapping = aes(x = NMDS1, y = NMDS2),
             colour = "black",
             alpha = 0) +
  geom_segment(data = subset(NMDS.MPRfort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.015, "npc"),
                             type = "closed"),
               colour = "darkgray",
               size = 0.8) +
  geom_text(data = subset(NMDS.MPRfort, Score == 'species'),
            mapping = aes(label = Label, x = NMDS1 * 1.1, y = NMDS2 * 1.1)) + 
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.8, colour = "gray") +
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.8, colour = "gray") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"))

#create a multi-panel plot with one column
ggarrange(MPRH1, MPRH2, ncol = 1)
```


########################################################## HASTA ACA REVISADO 22-08-2021 1:17 AM #####################################################################

## Test for differences in mite community composition across shrub level
Se necesita un dataframe con variable ambiental, se debe construir
```{r, echo=TRUE, message=TRUE, warning=TRUE}
summary(mite.env) #summary of each of the columns in this data
adonis(mite ~ Shrub, data = mite.env)

#then show this in the nmds plot
p3 <- ggplot() +
  geom_point(data = subset(fort, Score == 'sites'),
             mapping = aes(x = NMDS1, y = NMDS2, colour = mite.env$Shrub),
             alpha = 0.5) +
  geom_segment(data = subset(fort, Score == 'species'),
               mapping = aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.015, "npc"),
                             type = "closed"),
               colour = "darkgray",
               size = 0,
               alpha = 0) +
  geom_text(data = subset(fort, Score == 'species'),
            mapping = aes(label = Label, x = NMDS1 * 1.1, y = NMDS2 * 1.1),
            alpha = 0) +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 0.8, colour = "gray") +
  geom_vline(aes(xintercept = 0), linetype = "dashed", size = 0.8, colour = "gray") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"),
        legend.position = c(0.8, 0.2)) +
  scale_color_discrete("Shrubs")

jpeg("mite_NMDS.jpg", width = 150, height = 250, units = "mm", res = 600)
ggarrange(p3, p2, ncol = 1)
dev.off() #turning off the jpeg device
```
